{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/yphhcgv17dz3dwr2sc43_pwm0000gn/T/ipykernel_7292/2920153759.py:6: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import time\n",
    "import pypomp\n",
    "import unittest\n",
    "import jax.numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pykalman\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pypomp.mop import mop\n",
    "from pypomp.pfilter import pfilter\n",
    "from pypomp.internal_functions import _mop_internal\n",
    "from pypomp.internal_functions import _pfilter_internal\n",
    "from pypomp.internal_functions import _pfilter_internal_mean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Linear Gaussian Model: A comparison with Kalman-filtering algorithm\n",
    "\n",
    "Model Setup\n",
    "\n",
    "Kalman filter deals with the dynamic system:\n",
    "\\begin{align}\n",
    "    x_t &= A x_{t-1} + w_t \\\\\n",
    "    \\text{where} \\quad\n",
    "    x_t &\\text{ is the current state vector.} \\nonumber \\\\\n",
    "    A &\\text{ is the state transition matrix.} \\nonumber \\\\\n",
    "    w_t &\\sim \\mathcal{N}(0, Q) \\text{ is the process noise, normally distributed with mean 0 and covariance } Q. \\nonumber \\\\\n",
    "    y_t &= C x_t + v_t \\\\\n",
    "    \\text{where} \\quad\n",
    "    y_t &\\text{ is the current observation vector.} \\nonumber \\\\\n",
    "    C &\\text{ is the observation matrix.} \\nonumber \\\\\n",
    "    v_t &\\sim \\mathcal{N}(0, R) \\text{ is the observation noise, normally distributed with mean 0 and covariance} R. \\nonumber\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Set T (Time Length) to be 1000 and generate linear Gaussian states and observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_thetas(theta):\n",
    "    A = theta[0:4].reshape(2, 2)\n",
    "    C = theta[4:8].reshape(2, 2)\n",
    "    Q = theta[8:12].reshape(2, 2)\n",
    "    R = theta[12:16].reshape(2, 2)\n",
    "    return A, C, Q, R\n",
    "\n",
    "def transform_thetas(A, C, Q, R):\n",
    "    return np.concatenate([A.flatten(), C.flatten(), Q.flatten(), R.flatten()])\n",
    "\n",
    "\n",
    "fixed = False\n",
    "key = jax.random.PRNGKey(111)\n",
    "angle = 0.2\n",
    "angle2 = angle if fixed else -0.5\n",
    "A = np.array([[np.cos(angle2), -np.sin(angle)],\n",
    "             [np.sin(angle), np.cos(angle2)]])\n",
    "C = np.eye(2)\n",
    "Q = np.array([[1, 1e-4],\n",
    "             [1e-4, 1]]) #/ 100\n",
    "R = np.array([[1, .1],\n",
    "            [.1, 1]]) #/ 10\n",
    "     \n",
    "theta = transform_thetas(A, C, Q, R)\n",
    "\n",
    "def generate_data(N, key):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    x = np.ones(2)\n",
    "    for i in tqdm(range(N)):\n",
    "        key, subkey = jax.random.split(key)\n",
    "        x = jax.random.multivariate_normal(key=subkey, mean=A @ x, cov=Q)\n",
    "        key, subkey = jax.random.split(key)\n",
    "        y = jax.random.multivariate_normal(key=subkey, mean=C @ x, cov=R)\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    xs = np.array(xs)\n",
    "    ys = np.array(ys)\n",
    "    return xs, ys, key\n",
    "\n",
    "def custom_rinit(theta, J, covars=None):\n",
    "    return np.ones((J, 2))\n",
    "\n",
    "def custom_rproc(state, theta, key, covars=None):\n",
    "    A, C, Q, R = get_thetas(theta)\n",
    "    key, subkey = jax.random.split(key)\n",
    "    return jax.random.multivariate_normal(key=subkey,\n",
    "                                          mean=A @ state, cov=Q)\n",
    "def custom_dmeas(y, preds, theta):\n",
    "    A, C, Q, R = get_thetas(theta)\n",
    "    return jax.scipy.stats.multivariate_normal.logpdf(y, preds, R)\n",
    "\n",
    "rinit = custom_rinit\n",
    "rproc = custom_rproc\n",
    "dmeas = custom_dmeas\n",
    "rprocess = jax.vmap(custom_rproc, (0, None, 0, None))\n",
    "dmeasure = jax.vmap(custom_dmeas, (None, 0, None))\n",
    "rprocesses = jax.vmap(custom_rproc, (0, 0, 0, None))\n",
    "dmeasures = jax.vmap(custom_dmeas, (None, 0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logmeanexp(x):\n",
    "   x_array = np.array(x)\n",
    "   x_max = np.max(x_array)\n",
    "   log_mean_exp = np.log(np.mean(np.exp(x_array - x_max))) + x_max\n",
    "   return log_mean_exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set J=10,000 (number of particles) and compare the estimated log-likelihood between Kalman filtering and the log-mean-exponential computed over 100 replications for various methods, including classical particle filtering and MOP, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 2654.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kf loglik = -3759.064178842396\n"
     ]
    }
   ],
   "source": [
    "xs, ys, key = generate_data(1000, key)\n",
    "kf = pykalman.KalmanFilter(transition_matrices=A, observation_matrices=C, \n",
    "                        transition_covariance=Q, observation_covariance=R)\n",
    "print(\"kf loglik =\", kf.loglikelihood(ys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logmeanexp of Particle Filtering = -3759.153\n",
      "difference between Kalman-Filtering and logmeanexp of Particle Filtering = 0.08886719\n"
     ]
    }
   ],
   "source": [
    "loglike = []\n",
    "for i in range(100):  \n",
    "    key, subkey = jax.random.split(key)\n",
    "    pfilter_val = -_pfilter_internal(theta, ys, J = 10000, rinit = rinit, rprocess = rprocess, dmeasure = dmeasure, covars = None,\n",
    "                                   key= key, thresh = -1)\n",
    "    loglike.append(pfilter_val)\n",
    "\n",
    "loglike_ = np.array(loglike)\n",
    "print(\"Logmeanexp of Particle Filtering =\", logmeanexp(loglike))\n",
    "print(\"difference between Kalman-Filtering and logmeanexp of Particle Filtering =\", kf.loglikelihood(ys) - (logmeanexp(loglike)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By calculating the difference between Kalman-filtering and Paticle Filtering algorithm, we discovered that the value of difference can reach 0.089, indicating that we get a reasonable inference result from the MOP algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0, Logmeanexp: -3759.23095703125, Difference: 0.166748046875\n",
      "Alpha: 0.1, Logmeanexp: -3759.15087890625, Difference: 0.086669921875\n",
      "Alpha: 0.3, Logmeanexp: -3759.229248046875, Difference: 0.1650390625\n",
      "Alpha: 0.6, Logmeanexp: -3759.072265625, Difference: 0.008056640625\n",
      "Alpha: 0.9, Logmeanexp: -3759.102294921875, Difference: 0.0380859375\n",
      "Alpha: 1, Logmeanexp: -3759.331298828125, Difference: 0.26708984375\n"
     ]
    }
   ],
   "source": [
    "alphas = [0, 0.1, 0.3, 0.6, 0.9, 1]  \n",
    "results = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    loglike_mop = []\n",
    "    for i in range(100):  \n",
    "        key, subkey = jax.random.split(key)\n",
    "        mop_val = -_mop_internal(theta, ys, J=10000, rinit=rinit, rprocess=rprocess, dmeasure=dmeasure, covars=None,\n",
    "                                 key=key, alpha=alpha)\n",
    "        loglike_mop.append(mop_val)\n",
    "\n",
    "    loglike_mop = np.array(loglike_mop)\n",
    "    logmeanexp_val = logmeanexp(loglike_mop)\n",
    "    difference = kf.loglikelihood(ys) - logmeanexp_val\n",
    "    \n",
    "    results.append((alpha, logmeanexp_val, difference))\n",
    "    print(f\"Alpha: {alpha}, Logmeanexp: {logmeanexp_val}, Difference: {difference}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By calculating the difference between the Kalman-filtering and MOP algorithm estimates for different values of $\\alpha$, we observed that the maginitude varies without an obvious trend as $\\alpha$ increases from 0 to 1. The maginitude reaches its minimum with 0.008 when $\\alpha = 0.6$, suggesting that the MOP algorithm has the potential to provide an inference results that are highly consistent with those from the Kalman filtering method when choosing $\\alpha$ appropriately.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Linear Gaussian Model: How estimate logllikehood difference and running time varys among different T and J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_values = [1000, 5000]  \n",
    "J_values = [10, 100, 1000, 10000]  \n",
    "\n",
    "results = []\n",
    "key = jax.random.PRNGKey(112)\n",
    "\n",
    "for N in N_values:\n",
    "    for J in J_values:\n",
    "        print(f\"Running with N={N}, J={J}...\")\n",
    "        \n",
    "        xs, ys, key = generate_data(N, key)\n",
    "        pf_loglik_arr = []\n",
    "        mop_loglik_arr = []\n",
    "        elapsed_time1_arr = []\n",
    "        elapsed_time2_arr = []\n",
    "        \n",
    "        for i in range(100):  \n",
    "            start_time = time.time()\n",
    "            pf_val = -pfilter(J = J, rinit = rinit, rprocess = rprocess, dmeasure = dmeasure, theta = theta, ys = ys, thresh = 0, key = key)\n",
    "            pf_loglik_arr.append(pf_val)\n",
    "            elapsed_time1_arr.append(time.time() - start_time)\n",
    "\n",
    "            start_time2 = time.time()\n",
    "            mop_val = -mop(J = J, rinit = rinit, rprocess = rprocess, dmeasure = dmeasure, theta = theta, ys = ys, alpha = 0.9, key = key)\n",
    "            mop_loglik_arr.append(mop_val)\n",
    "            elapsed_time2_arr.append(time.time() - start_time2)\n",
    "        \n",
    "        pf_loglik_arr = np.array(pf_loglik_arr)\n",
    "        mop_loglik_arr = np.array(mop_loglik_arr)\n",
    "        elapsed_time1_arr = np.array(elapsed_time1_arr)\n",
    "        elapsed_time2_arr = np.array(elapsed_time2_arr)\n",
    "\n",
    "        results.append({\n",
    "            'N': N, \n",
    "            'J': J, \n",
    "            'pf_loglik': logmeanexp(pf_loglik_arr), \n",
    "            'time_pfilter': np.mean(elapsed_time1_arr), \n",
    "            'mop_loglik': logmeanexp(mop_loglik_arr), \n",
    "            'time_mop': np.mean(elapsed_time2_arr), \n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'N': 1000,\n",
       "  'J': 10,\n",
       "  'pf_loglik': Array(-4059.384, dtype=float32),\n",
       "  'time_pfilter': Array(0.00262911, dtype=float32),\n",
       "  'mop_loglik': Array(-4044.6467, dtype=float32),\n",
       "  'time_mop': Array(0.01157162, dtype=float32)},\n",
       " {'N': 1000,\n",
       "  'J': 100,\n",
       "  'pf_loglik': Array(-3766.4568, dtype=float32),\n",
       "  'time_pfilter': Array(0.03207133, dtype=float32),\n",
       "  'mop_loglik': Array(-3776.5305, dtype=float32),\n",
       "  'time_mop': Array(0.0302381, dtype=float32)},\n",
       " {'N': 1000,\n",
       "  'J': 1000,\n",
       "  'pf_loglik': Array(-3747.1902, dtype=float32),\n",
       "  'time_pfilter': Array(0.3003823, dtype=float32),\n",
       "  'mop_loglik': Array(-3744.5942, dtype=float32),\n",
       "  'time_mop': Array(0.4241002, dtype=float32)},\n",
       " {'N': 1000,\n",
       "  'J': 10000,\n",
       "  'pf_loglik': Array(-3724.4568, dtype=float32),\n",
       "  'time_pfilter': Array(2.2342062, dtype=float32),\n",
       "  'mop_loglik': Array(-3724.7112, dtype=float32),\n",
       "  'time_mop': Array(3.1925905, dtype=float32)},\n",
       " {'N': 1000,\n",
       "  'J': 100000,\n",
       "  'pf_loglik': Array(-3797.8877, dtype=float32),\n",
       "  'time_pfilter': Array(17.238829, dtype=float32),\n",
       "  'mop_loglik': Array(-3797.6775, dtype=float32),\n",
       "  'time_mop': Array(16.385502, dtype=float32)},\n",
       " {'N': 5000,\n",
       "  'J': 10,\n",
       "  'pf_loglik': Array(-20326.46, dtype=float32),\n",
       "  'time_pfilter': Array(0.02121412, dtype=float32),\n",
       "  'mop_loglik': Array(-20303.664, dtype=float32),\n",
       "  'time_mop': Array(0.02167264, dtype=float32)},\n",
       " {'N': 5000,\n",
       "  'J': 100,\n",
       "  'pf_loglik': Array(-18856.922, dtype=float32),\n",
       "  'time_pfilter': Array(0.09896883, dtype=float32),\n",
       "  'mop_loglik': Array(-18853.13, dtype=float32),\n",
       "  'time_mop': Array(0.10377918, dtype=float32)},\n",
       " {'N': 5000,\n",
       "  'J': 1000,\n",
       "  'pf_loglik': Array(-18803.223, dtype=float32),\n",
       "  'time_pfilter': Array(1.323793, dtype=float32),\n",
       "  'mop_loglik': Array(-18808.762, dtype=float32),\n",
       "  'time_mop': Array(1.9390032, dtype=float32)},\n",
       " {'N': 5000,\n",
       "  'J': 10000,\n",
       "  'pf_loglik': Array(-18672.562, dtype=float32),\n",
       "  'time_pfilter': Array(10.692378, dtype=float32),\n",
       "  'mop_loglik': Array(-18672.344, dtype=float32),\n",
       "  'time_mop': Array(15.778171, dtype=float32)}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result (To Be Continued):\n",
    "\n",
    "\\begin{array}{|c|c|c|c|c|c|}\n",
    "\\hline\n",
    "\\textbf{N} & \\textbf{J} & \\textbf{Particle Filter Loglik} & \\textbf{Time (Particle Filter)} & \\textbf{MOP Loglik} & \\textbf{Time (MOP)} \\\\\n",
    "\\hline\n",
    "1000 & 10 & -4059.384 & 0.00262911 & -4044.6467 & 0.01157162 \\\\\n",
    "1000 & 100 & -3766.4568 & 0.03207133 & -3776.5305 & 0.0302381 \\\\\n",
    "1000 & 1000 & -3747.1902 & 0.3003823 & -3744.5942 & 0.4241002 \\\\\n",
    "1000 & 10000 & -3724.4568 & 2.2342062 & -3724.7112 & 3.1925905 \\\\\n",
    "1000 & 100000 & -3797.8877 & 17.238829 & -3797.6775 & 16.385502 \\\\\n",
    "5000 & 10 & -20326.46 & 0.02121412 & -20303.664 & 0.02167264 \\\\\n",
    "5000 & 100 & -18856.922 & 0.09896883 & -18853.13 & 0.10377918 \\\\\n",
    "5000 & 1000 & -18803.223 & 1.323793 & -18808.762 & 1.9390032 \\\\\n",
    "5000 & 10000 & -18672.562 & 10.692378 & -18672.344 & 15.778171 \\\\\n",
    "\\hline\n",
    "\\end{array}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
